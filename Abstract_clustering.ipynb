{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detección de Idiomas en el Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura de Librerías\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YORLEY\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Leyendo los abstracts\n",
    "df = pd.read_csv(r'Data\\scopus_con_indicadores.csv',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remover Stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\YORLEY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import *\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46837, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Abstracts = df[['Title','Abstract']].drop_duplicates()\n",
    "Abstracts[\"Abstract\"] = Abstracts[\"Abstract\"].str.lower().str.split()\n",
    "Abstracts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2285290042559306\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "Abstracts['Clean_Abstract'] = Abstracts['Abstract'] \\\n",
    ".apply(lambda x: [item for item in x if item not in stop])\n",
    "end = time.time()\n",
    "print((end-start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Abstracts['Clean_Abstract'] = Abstracts['Abstract'] \\\n",
    ".apply(lambda x: ' '.join([word for word in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Clean_Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>C- And Sr-isotope stratigraphy of the São Caet...</td>\n",
       "      <td>[c-isotope, and, 87sr/86sr, values, for, five,...</td>\n",
       "      <td>c-isotope and 87sr/86sr values for five carbon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Morphosynthesis: High fidelity inorganic repli...</td>\n",
       "      <td>[high, fidelity, calcium, carbonate, and, hydr...</td>\n",
       "      <td>high fidelity calcium carbonate and hydroxyapa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>A reassessment of the role of serotonergic sys...</td>\n",
       "      <td>[the, role, of, serotonergic, system, in, the,...</td>\n",
       "      <td>the role of serotonergic system in the feeding...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Animal-based medicines: Biological prospection...</td>\n",
       "      <td>[animals, have, been, used, as, medicinal, res...</td>\n",
       "      <td>animals have been used as medicinal resources ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Determining sexual dimorphism in frog measurem...</td>\n",
       "      <td>[several, analytic, techniques, have, been, us...</td>\n",
       "      <td>several analytic techniques have been used to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Mammalian cell invasion and intracellular traf...</td>\n",
       "      <td>[trypanosoma, cruzi,, the, etiological, agent,...</td>\n",
       "      <td>trypanosoma cruzi, the etiological agent of ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Mineral chemistry of tantalate species new in ...</td>\n",
       "      <td>[tantalate, samples,, supposedly, of, the, col...</td>\n",
       "      <td>tantalate samples, supposedly of the columbite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Complementary Lagrangians in infinite dimensio...</td>\n",
       "      <td>[we, prove, that, any, countable, family, of, ...</td>\n",
       "      <td>we prove that any countable family of lagrangi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Chemical and mineralogical characterization of...</td>\n",
       "      <td>[the, alto, quixaba, pegmatite,, seridó, regio...</td>\n",
       "      <td>the alto quixaba pegmatite, seridó region, nor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>General optimal euclidean Sobolev and Gagliard...</td>\n",
       "      <td>[we, prove, general, optimal, euclidean, sobol...</td>\n",
       "      <td>we prove general optimal euclidean sobolev and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "35  C- And Sr-isotope stratigraphy of the São Caet...   \n",
       "39  Morphosynthesis: High fidelity inorganic repli...   \n",
       "41  A reassessment of the role of serotonergic sys...   \n",
       "46  Animal-based medicines: Biological prospection...   \n",
       "47  Determining sexual dimorphism in frog measurem...   \n",
       "49  Mammalian cell invasion and intracellular traf...   \n",
       "57  Mineral chemistry of tantalate species new in ...   \n",
       "62  Complementary Lagrangians in infinite dimensio...   \n",
       "64  Chemical and mineralogical characterization of...   \n",
       "68  General optimal euclidean Sobolev and Gagliard...   \n",
       "\n",
       "                                             Abstract  \\\n",
       "35  [c-isotope, and, 87sr/86sr, values, for, five,...   \n",
       "39  [high, fidelity, calcium, carbonate, and, hydr...   \n",
       "41  [the, role, of, serotonergic, system, in, the,...   \n",
       "46  [animals, have, been, used, as, medicinal, res...   \n",
       "47  [several, analytic, techniques, have, been, us...   \n",
       "49  [trypanosoma, cruzi,, the, etiological, agent,...   \n",
       "57  [tantalate, samples,, supposedly, of, the, col...   \n",
       "62  [we, prove, that, any, countable, family, of, ...   \n",
       "64  [the, alto, quixaba, pegmatite,, seridó, regio...   \n",
       "68  [we, prove, general, optimal, euclidean, sobol...   \n",
       "\n",
       "                                       Clean_Abstract  \n",
       "35  c-isotope and 87sr/86sr values for five carbon...  \n",
       "39  high fidelity calcium carbonate and hydroxyapa...  \n",
       "41  the role of serotonergic system in the feeding...  \n",
       "46  animals have been used as medicinal resources ...  \n",
       "47  several analytic techniques have been used to ...  \n",
       "49  trypanosoma cruzi, the etiological agent of ch...  \n",
       "57  tantalate samples, supposedly of the columbite...  \n",
       "62  we prove that any countable family of lagrangi...  \n",
       "64  the alto quixaba pegmatite, seridó region, nor...  \n",
       "68  we prove general optimal euclidean sobolev and...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Abstracts[10:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The common way of doing this is to transform the documents into tf-idf vectors, \n",
    "then compute the cosine similarity between them. Any textbook on information retrieval (IR) covers this. See esp. Introduction to Information Retrieval, which is free and available online.\n",
    "\n",
    "Tf-idf (and similar text transformations) are implemented in the Python packages\n",
    "Gensim and scikit-learn. In the latter package, computing cosine similarities is as easy as\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11911589701970418\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "abstracts = Abstracts['Clean_Abstract']\n",
    "#stopwords_ = [word.decode('utf-8') for word in stopwords.words('english')]\n",
    "tfidf = TfidfVectorizer().fit_transform(abstracts)\n",
    "# no need to normalize, since Vectorizer will return normalized tf-idf\n",
    "end = time.time()\n",
    "print((end-start)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La siguiente es la actividad que más recursos consume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=time.time()\n",
    "pairwise_similarity = tfidf * tfidf.T\n",
    "end = time.time()\n",
    "print((end-start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.19398492, 0.16123592, 0.14078741, 0.11287005,\n",
       "        0.1569428 , 0.19655586, 0.08490813, 0.16734285, 0.09044775],\n",
       "       [0.19398492, 1.        , 0.22201381, 0.25308875, 0.15308845,\n",
       "        0.24607412, 0.29720889, 0.20322919, 0.19696537, 0.1060546 ],\n",
       "       [0.16123592, 0.22201381, 1.        , 0.1698412 , 0.10125079,\n",
       "        0.17649501, 0.22828566, 0.10923815, 0.154202  , 0.1212646 ],\n",
       "       [0.14078741, 0.25308875, 0.1698412 , 1.        , 0.18380305,\n",
       "        0.23718104, 0.21522158, 0.17889136, 0.15634494, 0.10018152],\n",
       "       [0.11287005, 0.15308845, 0.10125079, 0.18380305, 1.        ,\n",
       "        0.14892747, 0.15749963, 0.11829638, 0.11773911, 0.08057711],\n",
       "       [0.1569428 , 0.24607412, 0.17649501, 0.23718104, 0.14892747,\n",
       "        1.        , 0.23921886, 0.12747713, 0.18373387, 0.09822092],\n",
       "       [0.19655586, 0.29720889, 0.22828566, 0.21522158, 0.15749963,\n",
       "        0.23921886, 1.        , 0.16066129, 0.215984  , 0.1122158 ],\n",
       "       [0.08490813, 0.20322919, 0.10923815, 0.17889136, 0.11829638,\n",
       "        0.12747713, 0.16066129, 1.        , 0.09407479, 0.07514354],\n",
       "       [0.16734285, 0.19696537, 0.154202  , 0.15634494, 0.11773911,\n",
       "        0.18373387, 0.215984  , 0.09407479, 1.        , 0.10439824],\n",
       "       [0.09044775, 0.1060546 , 0.1212646 , 0.10018152, 0.08057711,\n",
       "        0.09822092, 0.1122158 , 0.07514354, 0.10439824, 1.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairwise_similarity.A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Otras posibles Opciones\n",
    "https://stackoverflow.com/questions/51591510/text-similarity-approaches-do-not-reflect-real-similarity-between-texts\n",
    "https://stackoverflow.com/questions/8897593/how-to-compute-the-similarity-between-two-text-documents\n",
    "https://stackoverflow.com/questions/101569/algorithm-to-detect-similar-documents-in-python-script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Apuntes\n",
    "#https://stackoverflow.com/questions/25443802/unicode-warning-when-using-nltk-stopwords-with-tfidfvectorizer-of-scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import SpectralClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat= np.matrix(pairwise_similarity.A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YORLEY\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\spectral.py:462: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, 0, 0, 1, 0, 2, 0, 0, 2, 2, 2, 0, 2, 0, 0, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 0, 0, 2, 2, 2, 0, 0, 2, 2, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0,\n",
       "       2, 2, 0, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 2, 0, 2, 2, 2, 2, 0, 0,\n",
       "       2, 0, 0, 0, 2, 2, 2, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2,\n",
       "       2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SpectralClustering(3).fit_predict(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
